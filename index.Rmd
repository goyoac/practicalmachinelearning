---
title: "Practical Machine Learning Course Project"
author: "Gregorio Ambrosio Cestero"
date: "March 22, 2016"
output: 
  html_document: 
    keep_md: yes
---

## Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.

More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

## Goal

The 5 different ways were labeled as A,B,C,D and E. The goal of this project is to predict the manner in which they did the exercise, i.e., the variable classe (A to E).

## Summary

A random forest machine learning model was built using 5-fold cross-validation based on a training dataset.

## Loading data and needed packages

First of all, as usual, we load the R packages needed for the code and then download the training and testing data sets.

```{r warning=FALSE, message=FALSE}
# Needed packages

library(ggplot2)
library(caret)
library(randomForest)

# Loading data

pmlTrainingFile <- "pml-training.csv"
pmlTestFile     <- "pml-testing.csv"

pmlTrainingUrl  <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
pmlTestUrl      <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

if (!file.exists(pmlTrainingFile)) {
  download.file(pmlTrainingUrl, pmlTrainingFile, method="curl")
}

if (!file.exists(pmlTestFile)) {
  download.file(pmlTestUrl, pmlTestFile, method="curl")
}

pmlTraining <- read.csv(pmlTrainingFile, na.strings = c("", "NA", "#DIV/0!"))
pmlTesting  <- read.csv(pmlTestFile,     na.strings = c("", "NA", "#DIV/0!"))
```

Training data has 19622 rows of 160 variables, while testing data has only 20 rows of the same number of variables.

## Preparing data

We remove variables with missing or empty values and, after that, we remove unnecessary variables (predictors) getting a final set of 53 variables. 

Finally, we split the training data set into train data and validation data with a rate of 70:30. The validation data let us to compute the out-of-sample error. 

```{r}
## Removing variables with NAs or empty
pmlTraining.cleaned <- pmlTraining [, colSums(is.na(pmlTraining)) == 0]
pmlTesting.cleaned  <- pmlTesting  [, colSums(is.na(pmlTesting))  == 0]


## Removing unnecessary variables
colsNotNeeded <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
pmlTraining.cleaned <- pmlTraining.cleaned [, -which(names(pmlTraining.cleaned) %in% colsNotNeeded)]
pmlTesting.cleaned  <- pmlTesting.cleaned  [, -which(names(pmlTesting.cleaned)  %in% colsNotNeeded)]

## Spliting training data
set.seed(1111)
toTrain <- createDataPartition(pmlTraining.cleaned$classe, p=0.7, list=FALSE)
pmlTraining.cleaned.trainSet      <- pmlTraining.cleaned[ toTrain, ]
pmlTraining.cleaned.validationSet <- pmlTraining.cleaned[-toTrain, ]
```

## Modeling & Results

For our prediction algorithm we use random forest method. We use this machine learning model with 5-fold cross validation, saving some computing time.

```{r}
pmlModelRandomForest <- train(classe ~ .,
                              data          = pmlTraining.cleaned.trainSet,
                              method        = "rf",
                              trControl     = trainControl(method="cv", number=5)
)
pmlModelRandomForest
```

We test the model on the validation dataset and get the confusion matrix.

```{r}
validationPredictRandomForest <- predict(pmlModelRandomForest, pmlTraining.cleaned.validationSet)
confMatrixRndomForest <- confusionMatrix(pmlTraining.cleaned.validationSet$classe, validationPredictRandomForest)
confMatrixRndomForest

outOfSampleError <- sum(validationPredictRandomForest != pmlTraining.cleaned.validationSet$classe)/ nrow(pmlTraining.cleaned.validationSet)
outOfSampleError
```
The estimated accuracy of the model on the validation dataset is `r round(confMatrixRndomForest$overall[1]*100, 2)` % and the estimated out of sample error is `r round (sum(validationPredictRandomForest != pmlTraining.cleaned.validationSet$classe) * 100 / nrow(pmlTraining.cleaned.validationSet),2)`%.

## Testing

This model is able to predict 100% of the 20 cases provided in the testing dataset.

## Some plots
```{r}
plot(varImp(pmlModelRandomForest), main = "Top 10 predictors", top = 10)
plot(pmlModelRandomForest, main="Model accuracy by predictors")
```


